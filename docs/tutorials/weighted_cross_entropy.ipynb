{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bokbokbok.loss_functions.classification import WeightedCrossEntropyLoss\n",
    "from bokbokbok.eval_metrics.classification import WeightedCrossEntropyMetric\n",
    "\n",
    "X, y = make_classification(n_samples=1000, \n",
    "                           n_features=10, \n",
    "                           random_state=41114)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, \n",
    "                                                      y, \n",
    "                                                      test_size=0.25, \n",
    "                                                      random_state=41114)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage in LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train = lgb.Dataset(X_train, y_train)\n",
    "valid = lgb.Dataset(X_valid, y_valid, reference=train)\n",
    "params_wce = {\n",
    "     'n_estimators': 300,\n",
    "     'seed': 41114,\n",
    "     'n_jobs': 8,\n",
    "     'learning_rate': 0.1,\n",
    "   }\n",
    "\n",
    "wce_clf = lgb.train(params=params_wce,\n",
    "                train_set=train,\n",
    "                valid_sets=[train, valid],\n",
    "                valid_names=['train','valid'],\n",
    "                fobj=WeightedCrossEntropyLoss(alpha=0.7),\n",
    "                feval=WeightedCrossEntropyMetric(alpha=0.7),\n",
    "                early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "\n",
    "params = {\n",
    "     'seed': 41114,\n",
    "     'learning_rate': 0.1,\n",
    "    'disable_default_eval_metric': 1\n",
    "   }\n",
    "\n",
    "bst = xgb.train(params,\n",
    "          dtrain=dtrain,\n",
    "          num_boost_round=300,\n",
    "          early_stopping_rounds=10,\n",
    "          verbose_eval=10,\n",
    "          obj=WeightedCrossEntropyLoss(alpha=1.0),\n",
    "          maximize=False,\n",
    "          feval=WeightedCrossEntropyMetric(alpha=1.0, XGBoost=True),\n",
    "          evals=[(dtrain, 'dtrain'), (dvalid, 'dvalid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skorecard_py37]",
   "language": "python",
   "name": "conda-env-skorecard_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
